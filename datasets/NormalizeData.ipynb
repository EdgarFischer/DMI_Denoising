{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600129ff",
   "metadata": {},
   "source": [
    "The sole purpose of this file is to convert the CombinedCSI.mat file from the pipeline to a separate data.npy and mask.npy files for easier usage. You only have to insert the correct data folder name below and run the notebook. A CombinedCSI.mat file in that folder is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4205925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def normalize_with_reference(folder_list, base_path=\".\"):\n",
    "    \"\"\"\n",
    "    Normiert alle data.npy in folder_list mit demselben Faktor,\n",
    "    der aus dem Referenz-Ordner (erster in der Liste) kommt.\n",
    "    \n",
    "    Args:\n",
    "        folder_list (list of str): Liste von Ordnernamen, die 'data.npy' enthalten.\n",
    "        base_path (str): Pfad, unter dem die Ordner liegen.\n",
    "    \"\"\"\n",
    "    if not folder_list:\n",
    "        raise ValueError(\"folder_list darf nicht leer sein.\")\n",
    "\n",
    "    # Referenzordner = erster in der Liste\n",
    "    ref_folder = folder_list[0]\n",
    "    ref_path   = os.path.join(base_path, ref_folder, \"data.npy\")\n",
    "    if not os.path.isfile(ref_path):\n",
    "        raise FileNotFoundError(f\"Referenzdatei nicht gefunden: {ref_path}\")\n",
    "\n",
    "    # Lade Referenzdaten\n",
    "    ref_data = np.load(ref_path)\n",
    "    ref_max  = np.max(np.abs(ref_data))\n",
    "    if ref_max <= 0:\n",
    "        raise ValueError(\"Referenz hat keinen positiven Betrag zum Normieren.\")\n",
    "    print(f\"[INFO] Referenz {ref_folder}: max(|data|) = {ref_max:.4e}\")\n",
    "\n",
    "    # Normiere alle Ordner\n",
    "    for fold in folder_list:\n",
    "        in_path  = os.path.join(base_path, fold, \"data.npy\")\n",
    "        out_dir  = os.path.join(base_path, fold + \"_normalized\")\n",
    "        out_path = os.path.join(out_dir, \"data.npy\")\n",
    "\n",
    "        if not os.path.isfile(in_path):\n",
    "            print(f\"[WARN] Überspringe {fold}, keine data.npy gefunden.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        arr = np.load(in_path)\n",
    "        arr_norm = arr / ref_max\n",
    "\n",
    "        np.save(out_path, arr_norm)\n",
    "        print(f\"[OK] {fold} → {out_path}\")\n",
    "\n",
    "    # Speichere den Referenzfaktor in eine Datei\n",
    "    factor_path = os.path.join(base_path, \"normalization_factor.txt\")\n",
    "    with open(factor_path, \"w\") as f:\n",
    "        f.write(f\"{ref_max:.6e}\\n\")\n",
    "    print(f\"[INFO] Normierungsfaktor gespeichert in {factor_path}\")\n",
    "# Beispielaufruf:\n",
    "# folders = [\"RefFolder\", \"Other1\", \"Other2\"]\n",
    "# normalize_with_reference(folders, base_path=\"datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742e06bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Referenz Simulated_Lac_Random_GT: max(|data|) = 3.8227e+00\n",
      "[OK] Simulated_Lac_Random_GT → ./Simulated_Lac_Random_GT_normalized/data.npy\n",
      "[OK] Simulated_Lac_Random_1 → ./Simulated_Lac_Random_1_normalized/data.npy\n",
      "[OK] Simulated_Lac_Random_2 → ./Simulated_Lac_Random_2_normalized/data.npy\n",
      "[OK] Simulated_Lac_Random_3 → ./Simulated_Lac_Random_3_normalized/data.npy\n",
      "[OK] Simulated_Lac_Random_4 → ./Simulated_Lac_Random_4_normalized/data.npy\n",
      "[INFO] Normierungsfaktor gespeichert in ./normalization_factor.txt\n"
     ]
    }
   ],
   "source": [
    "folders = [\"Simulated_Lac_Random_GT\", \"Simulated_Lac_Random_1\", \"Simulated_Lac_Random_2\", \"Simulated_Lac_Random_3\", \"Simulated_Lac_Random_4\"]\n",
    "normalize_with_reference(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86aec554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def normalize_individually(folder_list, base_path=\".\"):\n",
    "    \"\"\"\n",
    "    Normiert jede data.npy in folder_list separat auf max(|data|)=1.\n",
    "    Speichert Ergebnis in Ordnern mit Suffix '_normalized'.\n",
    "    Legt in jedem Normalisierungsordner eine 'factor.txt' mit dem Wert ab.\n",
    "    \n",
    "    Args:\n",
    "        folder_list (list of str): Liste von Ordnernamen, die 'data.npy' enthalten.\n",
    "        base_path (str): Pfad, unter dem die Ordner liegen.\n",
    "    \"\"\"\n",
    "    for fold in folder_list:\n",
    "        in_path  = os.path.join(base_path, fold, \"data.npy\")\n",
    "        out_dir  = os.path.join(base_path, fold + \"_normalized\")\n",
    "        out_path = os.path.join(out_dir, \"data.npy\")\n",
    "\n",
    "        if not os.path.isfile(in_path):\n",
    "            print(f\"[WARN] Überspringe {fold}, keine data.npy gefunden.\")\n",
    "            continue\n",
    "\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        arr = np.load(in_path)\n",
    "        maxv = np.max(np.abs(arr))\n",
    "        if maxv <= 0:\n",
    "            print(f\"[WARN] {fold}: max(|data|) <= 0, Normierung übersprungen.\")\n",
    "            np.save(out_path, arr)\n",
    "            continue\n",
    "\n",
    "        arr_norm = arr / maxv\n",
    "        np.save(out_path, arr_norm)\n",
    "\n",
    "        # Speichere den Faktor in eine Datei im Normalisierungsordner\n",
    "        factor_path = os.path.join(out_dir, \"factor.txt\")\n",
    "        with open(factor_path, \"w\") as f:\n",
    "            f.write(f\"{maxv:.6e}\\n\")\n",
    "\n",
    "        print(f\"[OK] {fold}: normiert mit Faktor {maxv:.4e} → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7d6af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] P03: normiert mit Faktor 4.1643e+04 → ./P03_normalized/data.npy\n",
      "[OK] P04: normiert mit Faktor 4.8763e+04 → ./P04_normalized/data.npy\n",
      "[OK] P05: normiert mit Faktor 4.2078e+04 → ./P05_normalized/data.npy\n",
      "[OK] P06: normiert mit Faktor 5.5208e+04 → ./P06_normalized/data.npy\n",
      "[OK] P07: normiert mit Faktor 4.5706e+04 → ./P07_normalized/data.npy\n",
      "[OK] P08: normiert mit Faktor 4.5392e+04 → ./P08_normalized/data.npy\n"
     ]
    }
   ],
   "source": [
    "folders = [\"P03\", \"P04\", \"P05\", \"P06\", \"P07\", \"P08\"]\n",
    "normalize_individually(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e3b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"Simulated_Lesion_GT/Lesion_120pts.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5298ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "lac_img = nib.load(\"Lac_amp_map.nii\")   # oder .nii\n",
    "glx_img = nib.load(\"Glx_amp_map.nii\")\n",
    "\n",
    "lac = lac_img.get_fdata(dtype=np.float32)\n",
    "glx = glx_img.get_fdata(dtype=np.float32)\n",
    "\n",
    "# sichere Division (vermeidet /0)\n",
    "ratio = np.divide(lac, glx, out=np.zeros_like(lac, dtype=np.float32), where=glx!=0)\n",
    "\n",
    "# optional: ungültige/negative Werte maskieren\n",
    "ratio[~np.isfinite(ratio)] = 0\n",
    "ratio[glx <= 0] = 0\n",
    "\n",
    "ratio_img = nib.Nifti1Image(ratio.astype(np.float32), lac_img.affine, lac_img.header)\n",
    "nib.save(ratio_img, \"Lac_over_Glx_ratio.nii\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
